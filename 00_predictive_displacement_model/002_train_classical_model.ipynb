{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12642d3",
   "metadata": {},
   "source": [
    "# 1. LIBRERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588422a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc, roc_auc_score,\n",
    "    matthews_corrcoef, balanced_accuracy_score, cohen_kappa_score, \n",
    "    log_loss, brier_score_loss\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f2c6e9",
   "metadata": {},
   "source": [
    "# 2. GPU CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9cf46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TensorFlow not available - using CPU for all models\n"
     ]
    }
   ],
   "source": [
    "GPU_AVAILABLE = False\n",
    "XGBOOST_GPU_PARAMS = {}\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    \n",
    "    if gpus:\n",
    "        print(f\"\\n✓ GPU DETECTED:\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  • GPU {i}: {gpu.name}\")\n",
    "        \n",
    "        GPU_AVAILABLE = True\n",
    "        XGBOOST_GPU_PARAMS = {\n",
    "            'tree_method': 'hist',\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        print(\"  • XGBoost: Using CPU (more efficient for large datasets)\")\n",
    "        print(\"  • LightGBM: Using CPU\")\n",
    "        print(\"  • CatBoost: Using CPU\")\n",
    "    else:\n",
    "        print(\"\\n No GPU detected - using CPU\")\n",
    "        XGBOOST_GPU_PARAMS = {\n",
    "            'tree_method': 'hist',\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "except:\n",
    "    print(\"\\n TensorFlow not available - using CPU for all models\")\n",
    "    XGBOOST_GPU_PARAMS = {\n",
    "        'tree_method': 'hist',\n",
    "        'n_jobs': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2967342",
   "metadata": {},
   "source": [
    "# 3. CREATE FOLDER STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c0b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'db/02a_classical_models/saved_models',\n",
    "    'db/02a_classical_models/predictions',\n",
    "    'db/02a_classical_models/metrics',\n",
    "    'db/02a_classical_models/metrics/by_architecture',\n",
    "    'db/02a_classical_models/model_data/feature_importance',\n",
    "    'db/02a_classical_models/model_data/confusion_matrices',\n",
    "    'db/02a_classical_models/model_data/confusion_matrices/by_architecture',\n",
    "    'db/02a_classical_models/model_data/roc_data',\n",
    "    'db/02a_classical_models/model_data/roc_data/by_architecture',\n",
    "    'db/02a_classical_models/model_data/hyperparameters',\n",
    "    'db/02a_classical_models/model_data/architecture_comparisons',\n",
    "    'db/02a_classical_models/comparative_tables'\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c8813",
   "metadata": {},
   "source": [
    "# 4. LOAD CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420829a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaded: 5,696,308 records\n",
      "Columns: ['ESTADO_DEPTO', 'VIGENCIA', 'HECHO', 'SEXO', 'ETNIA', 'DISCAPACIDAD', 'CICLO_VITAL', 'EVENTOS', 'Desplazamiento_forzado_binaria', 'km_norte_sur', 'km_este_oeste', 'distancia_total']\n"
     ]
    }
   ],
   "source": [
    "output_file = 'db/01_cleaned_data/displacement_vs_others_final.csv'\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "print(f\"\\nData loaded: {len(df):,} records\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61c904",
   "metadata": {},
   "source": [
    "# 5. DATA PREPARATION (FULL PIPELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2432f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from category_encoders.target_encoder import TargetEncoder\n",
    "    HAS_TARGET_ENCODER = True\n",
    "except Exception:\n",
    "    HAS_TARGET_ENCODER = False\n",
    "    print(\"Category_encoders not available, will use frequency encoding\")\n",
    "\n",
    "predictor_vars = [# Categorical variables\n",
    "                  'ESTADO_DEPTO',                    \n",
    "                  'SEXO',            \n",
    "                  'ETNIA',           \n",
    "                  'DISCAPACIDAD',    \n",
    "                  'CICLO_VITAL', \n",
    "                  # Numeric variables\n",
    "                  'VIGENCIA',          \n",
    "                  'EVENTOS',\n",
    "                  'km_norte_sur', \n",
    "                  'km_este_oeste', \n",
    "                  'distancia_total'\n",
    "                  ]\n",
    "\n",
    "target_var = 'Desplazamiento_forzado_binaria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8f5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EVENTOS'] = pd.to_numeric(df['EVENTOS'], errors='coerce')\n",
    "df['VIGENCIA'] = pd.to_numeric(df['VIGENCIA'], errors='coerce')\n",
    "df['km_norte_sur'] = pd.to_numeric(df['km_norte_sur'], errors='coerce')\n",
    "df['km_este_oeste'] = pd.to_numeric(df['km_este_oeste'], errors='coerce')\n",
    "df['distancia_total'] = pd.to_numeric(df['distancia_total'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ac9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "missing = df[predictor_vars + [target_var]].isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(f\"\\nMissing values detected:\")\n",
    "    print(missing[missing > 0])\n",
    "    df = df.dropna(subset=predictor_vars + [target_var])\n",
    "    print(f\"Records after removing missing: {len(df):,}\")\n",
    "else:\n",
    "    print(\"\\nNo missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a090536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset prepared:\n",
      "Features: 10\n",
      "Samples: 5,696,308\n",
      "Categorical: ['SEXO', 'ETNIA', 'CICLO_VITAL', 'DISCAPACIDAD', 'ESTADO_DEPTO']\n",
      "Numeric: ['EVENTOS', 'VIGENCIA', 'km_norte_sur', 'km_este_oeste', 'distancia_total']\n"
     ]
    }
   ],
   "source": [
    "X = df[predictor_vars].copy()\n",
    "y = df[target_var].values\n",
    "\n",
    "categorical_cols = ['SEXO', 'ETNIA', 'CICLO_VITAL', 'DISCAPACIDAD', 'ESTADO_DEPTO']\n",
    "numeric_cols = ['EVENTOS', 'VIGENCIA', 'km_norte_sur', 'km_este_oeste', 'distancia_total']\n",
    "\n",
    "print(f\"\\nDataset prepared:\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {len(X):,}\")\n",
    "print(f\"Categorical: {categorical_cols}\")\n",
    "print(f\"Numeric: {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4908c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Class 0 (Others): 3,565,834 (62.60%)\n",
      "Class 1 (Displacement): 2,130,474 (37.40%)\n",
      "Imbalance ratio: 1.67:1\n"
     ]
    }
   ],
   "source": [
    "class_counts = pd.Series(y).value_counts()\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Class 0 (Others): {class_counts.get(0,0):,} ({class_counts.get(0,0)/len(y)*100:.2f}%)\")\n",
    "print(f\"Class 1 (Displacement): {class_counts.get(1,0):,} ({class_counts.get(1,0)/len(y)*100:.2f}%)\")\n",
    "if class_counts.get(1,0) > 0:\n",
    "    print(f\"Imbalance ratio: {class_counts.get(0,0)/class_counts.get(1,0):.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b86aa",
   "metadata": {},
   "source": [
    "## 5.1. CATEGORICAL CARDINALITY & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b62315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical analysis saved\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(df)\n",
    "cat_report = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    vals = X[col].astype(str).fillna(\"<<NA>>\")\n",
    "    n_unique = vals.nunique()\n",
    "    rel_card = n_unique / n_rows\n",
    "    top_freq = vals.value_counts(normalize=True).mul(100).head(5).to_dict()\n",
    "\n",
    "    if n_unique <= 30 and rel_card < 0.001:\n",
    "        method = 'onehot'\n",
    "    elif n_unique <= 200 and rel_card < 0.01:\n",
    "        method = 'ordinal'\n",
    "    else:\n",
    "        method = 'high_cardinality'\n",
    "\n",
    "    cat_report.append({\n",
    "        'variable': col,\n",
    "        'n_unique': n_unique,\n",
    "        'relative_cardinality': rel_card,\n",
    "        'recommended': method\n",
    "    })\n",
    "\n",
    "cat_report_df = pd.DataFrame(cat_report)\n",
    "cat_report_df.to_excel('db/02a_classical_models/model_data/categorical_cardinality_report.xlsx', \n",
    "                       index=False, engine='openpyxl')\n",
    "print(\"Categorical analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a6038",
   "metadata": {},
   "source": [
    "## 5.2. APPLYING CATEGORICAL TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e0adb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHot for: ['SEXO', 'ETNIA', 'CICLO_VITAL', 'DISCAPACIDAD']\n",
      "Ordinal for: ['ESTADO_DEPTO']\n",
      "Encoded categorical shape: (5696308, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['db/02a_classical_models/saved_models/categorical_encoders.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_parts = []\n",
    "encoders_saved = {}\n",
    "\n",
    "onehot_cols = cat_report_df[cat_report_df['recommended']=='onehot']['variable'].tolist()\n",
    "if onehot_cols:\n",
    "    print(f\"OneHot for: {onehot_cols}\")\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    ohe_arr = ohe.fit_transform(X[onehot_cols].astype(str))\n",
    "    ohe_cols = ohe.get_feature_names_out(onehot_cols)\n",
    "    df_ohe = pd.DataFrame(ohe_arr, columns=ohe_cols, index=X.index)\n",
    "    encoded_parts.append(df_ohe)\n",
    "    encoders_saved['onehot'] = ohe\n",
    "\n",
    "ordinal_cols = cat_report_df[cat_report_df['recommended']=='ordinal']['variable'].tolist()\n",
    "if ordinal_cols:\n",
    "    print(f\"Ordinal for: {ordinal_cols}\")\n",
    "    ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    ord_arr = ord_enc.fit_transform(X[ordinal_cols].astype(str))\n",
    "    df_ord = pd.DataFrame(ord_arr, columns=ordinal_cols, index=X.index)\n",
    "    encoded_parts.append(df_ord)\n",
    "    encoders_saved['ordinal'] = ord_enc\n",
    "\n",
    "high_card_cols = cat_report_df[cat_report_df['recommended']=='high_cardinality']['variable'].tolist()\n",
    "if high_card_cols:\n",
    "    print(f\"High-cardinality for: {high_card_cols}\")\n",
    "    if HAS_TARGET_ENCODER:\n",
    "        print(\"Using TargetEncoder\")\n",
    "        te = TargetEncoder(cols=high_card_cols)\n",
    "        df_te = te.fit_transform(X[high_card_cols].astype(str), y)\n",
    "        encoded_parts.append(df_te)\n",
    "        encoders_saved['target'] = te\n",
    "    else:\n",
    "        print(\"Using frequency encoding\")\n",
    "        df_freq_list = []\n",
    "        for col in high_card_cols:\n",
    "            freq = X[col].astype(str).value_counts(normalize=True)\n",
    "            df_freq_list.append(X[col].astype(str).map(freq).rename(col + \"_freq\"))\n",
    "        df_freq = pd.concat(df_freq_list, axis=1)\n",
    "        encoded_parts.append(df_freq)\n",
    "        encoders_saved['frequency'] = True\n",
    "\n",
    "covered = set(onehot_cols + ordinal_cols + high_card_cols)\n",
    "remaining = [c for c in categorical_cols if c not in covered]\n",
    "if remaining:\n",
    "    print(f\"Remaining (fallback ordinal): {remaining}\")\n",
    "    ord_enc2 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    df_rem = pd.DataFrame(ord_enc2.fit_transform(X[remaining].astype(str)), \n",
    "                         columns=remaining, index=X.index)\n",
    "    encoded_parts.append(df_rem)\n",
    "    encoders_saved['ordinal_fallback'] = ord_enc2\n",
    "\n",
    "X_categorical = pd.concat(encoded_parts, axis=1) if encoded_parts else pd.DataFrame(index=X.index)\n",
    "print(f\"Encoded categorical shape: {X_categorical.shape}\")\n",
    "joblib.dump(encoders_saved, 'db/02a_classical_models/saved_models/categorical_encoders.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a85524",
   "metadata": {},
   "source": [
    "## 5.3. NUMERIC ANALYSIS & SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37ac7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          variable    n_obs  n_unique         mean         std          min  \\\n",
      "0          EVENTOS  5696308      7289    31.632610  292.888315     0.000000   \n",
      "1         VIGENCIA  5696308        41  2007.242717   10.540738  1985.000000   \n",
      "2     km_norte_sur  5696308        32   101.850859  352.537701  -974.554705   \n",
      "3    km_este_oeste  5696308        32   -78.119007  213.316777  -846.071239   \n",
      "4  distancia_total  5696308        32   367.378485  226.414383     0.000000   \n",
      "\n",
      "            max       skew  outlier_ratio  log_transform_applied  \\\n",
      "0  35298.000000  36.828932       0.173847                   True   \n",
      "1   2025.000000  -0.182433       0.000000                  False   \n",
      "2    883.324167   0.241279       0.007131                  False   \n",
      "3    730.382024   1.171035       0.019222                  False   \n",
      "4   1217.988358   0.372751       0.008723                  False   \n",
      "\n",
      "    scaler_chosen  \n",
      "0    RobustScaler  \n",
      "1    MinMaxScaler  \n",
      "2  StandardScaler  \n",
      "3  StandardScaler  \n",
      "4    MinMaxScaler  \n",
      "Numeric analysis saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['db/02a_classical_models/saved_models/numeric_scalers.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_report = []\n",
    "scalers = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    s = X[col].dropna().astype(float)\n",
    "    n_obs = len(s)\n",
    "    n_unique = s.nunique()\n",
    "    mean, std = s.mean(), s.std()\n",
    "    minimum, maximum = s.min(), s.max()\n",
    "    skew = s.skew()\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    outliers = ((s < lower) | (s > upper)).sum()\n",
    "    outlier_ratio = outliers / n_obs if n_obs>0 else 0.0\n",
    "\n",
    "    log_transform = (abs(skew) > 2) and (minimum >= 0)\n",
    "\n",
    "    if outlier_ratio > 0.05:\n",
    "        scaler_choice, scaler = 'RobustScaler', RobustScaler()\n",
    "    else:\n",
    "        if (minimum >= 0) and (maximum <= 1e6):\n",
    "            scaler_choice, scaler = 'MinMaxScaler', MinMaxScaler()\n",
    "        else:\n",
    "            scaler_choice, scaler = 'StandardScaler', StandardScaler()\n",
    "\n",
    "    col_data = X[[col]].astype(float).copy()\n",
    "    if log_transform:\n",
    "        col_data = np.log1p(col_data.clip(lower=0))\n",
    "        col_data = col_data.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    scaled = scaler.fit_transform(col_data.fillna(0))\n",
    "    X[col] = pd.Series(scaled.ravel(), index=X.index)\n",
    "\n",
    "    numeric_report.append({\n",
    "        'variable': col,\n",
    "        'n_obs': int(n_obs),\n",
    "        'n_unique': int(n_unique),\n",
    "        'mean': float(mean),\n",
    "        'std': float(std),\n",
    "        'min': float(minimum),\n",
    "        'max': float(maximum),\n",
    "        'skew': float(skew),\n",
    "        'outlier_ratio': float(outlier_ratio),\n",
    "        'log_transform_applied': bool(log_transform),\n",
    "        'scaler_chosen': scaler_choice\n",
    "    })\n",
    "    scalers[col] = scaler\n",
    "\n",
    "numeric_report_df = pd.DataFrame(numeric_report)\n",
    "print(numeric_report_df)\n",
    "numeric_report_df.to_excel('db/02a_classical_models/model_data/numeric_analysis.xlsx', \n",
    "                           index=False, engine='openpyxl')\n",
    "print(\"Numeric analysis saved\")\n",
    "joblib.dump(scalers, 'db/02a_classical_models/saved_models/numeric_scalers.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f432f5b1",
   "metadata": {},
   "source": [
    "## 5.4. COMBINING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc8d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  • Final feature matrix: (5696308, 29)\n"
     ]
    }
   ],
   "source": [
    "X_final = pd.concat([X_categorical.reset_index(drop=True), \n",
    "                     X[numeric_cols].reset_index(drop=True)], axis=1)\n",
    "print(f\"  • Final feature matrix: {X_final.shape}\")\n",
    "\n",
    "feature_names = X_final.columns.tolist()\n",
    "pd.DataFrame({'Feature_Name': feature_names}).to_excel(\n",
    "    'db/02a_classical_models/model_data/feature_names.xlsx', \n",
    "    index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cea958",
   "metadata": {},
   "source": [
    "## 5.5. TRAIN/TEST SPLIT (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ba8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3,987,415\n",
      "Test: 1,708,893\n",
      "Data preparation completed\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train: {len(X_train):,}\")\n",
    "print(f\"Test: {len(X_test):,}\")\n",
    "\n",
    "split_info = pd.DataFrame({\n",
    "    'Set': ['Train','Test'],\n",
    "    'Size': [len(X_train), len(X_test)],\n",
    "    'Class_0': [(y_train==0).sum(), (y_test==0).sum()],\n",
    "    'Class_1': [(y_train==1).sum(), (y_test==1).sum()]\n",
    "})\n",
    "split_info.to_csv('db/02a_classical_models/model_data/train_test_split_info.csv', \n",
    "                  index=False)\n",
    "\n",
    "print(\"Data preparation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8de3b",
   "metadata": {},
   "source": [
    "# 6. CLASS IMBALANCE HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f730b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: \n",
      "\n",
      "Class 0: 0.799\n",
      "Class 1: 1.337\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(f\"Class weights: \\n\")\n",
    "print(f\"Class 0: {class_weight_dict[0]:.3f}\")\n",
    "print(f\"Class 1: {class_weight_dict[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231f35a",
   "metadata": {},
   "source": [
    "# 7. HELPER FUNCTIONS FOR COMPREHENSIVE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc12b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_metrics(model, model_name, arch_name, X_train, X_test, \n",
    "                                   y_train, y_test, training_time, feature_names):\n",
    "    \"\"\"Calculate comprehensive metrics for a classification model.\"\"\"\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    inference_start = time.time()\n",
    "    _ = model.predict(X_test)\n",
    "    inference_time = (time.time() - inference_start) / len(X_test) * 1000\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob_train = None\n",
    "        y_prob_test = None\n",
    "    \n",
    "    cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "    tn, fp, fn, tp = cm_test.ravel()\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    train_precision = precision_score(y_train, y_pred_train, zero_division=0)\n",
    "    test_precision = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "    train_recall = recall_score(y_train, y_pred_train, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "    train_f1 = f1_score(y_train, y_pred_train, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "    \n",
    "    train_specificity = cm_train[0, 0] / (cm_train[0, 0] + cm_train[0, 1]) if (cm_train[0, 0] + cm_train[0, 1]) > 0 else 0\n",
    "    test_specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    train_gmean = np.sqrt(train_recall * train_specificity)\n",
    "    test_gmean = np.sqrt(test_recall * test_specificity)\n",
    "    \n",
    "    train_mcc = matthews_corrcoef(y_train, y_pred_train)\n",
    "    test_mcc = matthews_corrcoef(y_test, y_pred_test)\n",
    "    \n",
    "    train_balanced_acc = balanced_accuracy_score(y_train, y_pred_train)\n",
    "    test_balanced_acc = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    train_kappa = cohen_kappa_score(y_train, y_pred_train)\n",
    "    test_kappa = cohen_kappa_score(y_test, y_pred_test)\n",
    "    \n",
    "    if y_prob_test is not None:\n",
    "        test_roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "        test_log_loss = log_loss(y_test, y_prob_test)\n",
    "        test_brier_score = brier_score_loss(y_test, y_prob_test)\n",
    "    else:\n",
    "        test_roc_auc = None\n",
    "        test_log_loss = None\n",
    "        test_brier_score = None\n",
    "    \n",
    "    model_size_mb = len(pickle.dumps(model)) / (1024 * 1024)\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    accuracy_gap = train_accuracy - test_accuracy\n",
    "    f1_gap = train_f1 - test_f1\n",
    "    precision_gap = train_precision - test_precision\n",
    "    recall_gap = train_recall - test_recall\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Architecture': arch_name,\n",
    "        \n",
    "        'Train_Accuracy': train_accuracy,\n",
    "        'Train_Precision': train_precision,\n",
    "        'Train_Recall': train_recall,\n",
    "        'Train_F1': train_f1,\n",
    "        'Train_Specificity': train_specificity,\n",
    "        'Train_G_Mean': train_gmean,\n",
    "        'Train_Balanced_Accuracy': train_balanced_acc,\n",
    "        'Train_MCC': train_mcc,\n",
    "        'Train_Kappa': train_kappa,\n",
    "        \n",
    "        'Test_Accuracy': test_accuracy,\n",
    "        'Test_Precision': test_precision,\n",
    "        'Test_Recall': test_recall,\n",
    "        'Test_F1': test_f1,\n",
    "        'Test_Specificity': test_specificity,\n",
    "        'Test_G_Mean': test_gmean,\n",
    "        'Test_Balanced_Accuracy': test_balanced_acc,\n",
    "        'Test_MCC': test_mcc,\n",
    "        'Test_Kappa': test_kappa,\n",
    "        \n",
    "        'Test_ROC_AUC': test_roc_auc,\n",
    "        'Test_Log_Loss': test_log_loss,\n",
    "        'Test_Brier_Score': test_brier_score,\n",
    "        \n",
    "        'Test_True_Negatives': int(tn),\n",
    "        'Test_False_Positives': int(fp),\n",
    "        'Test_False_Negatives': int(fn),\n",
    "        'Test_True_Positives': int(tp),\n",
    "        'Test_TN_Percentage': (tn / len(y_test)) * 100,\n",
    "        'Test_FP_Percentage': (fp / len(y_test)) * 100,\n",
    "        'Test_FN_Percentage': (fn / len(y_test)) * 100,\n",
    "        'Test_TP_Percentage': (tp / len(y_test)) * 100,\n",
    "        \n",
    "        'Accuracy_Gap_Train_Test': accuracy_gap,\n",
    "        'F1_Gap_Train_Test': f1_gap,\n",
    "        'Precision_Gap_Train_Test': precision_gap,\n",
    "        'Recall_Gap_Train_Test': recall_gap,\n",
    "        \n",
    "        'Training_Time_Minutes': training_time,\n",
    "        'Inference_Time_ms_per_sample': inference_time,\n",
    "        'Model_Size_MB': model_size_mb,\n",
    "        'Number_of_Features': n_features,\n",
    "        \n",
    "        'Total_Train_Samples': len(y_train),\n",
    "        'Total_Test_Samples': len(y_test)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred_test, y_prob_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482f5d4",
   "metadata": {},
   "source": [
    "# 8. DEFINING MODELS AND ARCHITECTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97945f8c",
   "metadata": {},
   "source": [
    "Due to the computer used for training not having a high capacity to train all models at once, a comment and uncomment strategy was implemented to train three architectures per model. To execute, the three architectures to be trained must be uncommented, and the rest must be left commented. All information is saved and will not be lost when training other models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d8865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active model: XGBoost_0\n"
     ]
    }
   ],
   "source": [
    "models_config = {\n",
    "    \n",
    "    # ============================================\n",
    "    # MODELO 1: LOGISTIC REGRESSION\n",
    "    # ============================================\n",
    "    # 'Logistic_Regression': {\n",
    "    #     'architectures': [\n",
    "    #         {\n",
    "    #             'name': 'Logistic_Regression_Architecture_1',\n",
    "    #             'params': {\n",
    "    #                 'C': 0.1,\n",
    "    #                 'penalty': 'l2',\n",
    "    #                 'solver': 'lbfgs',\n",
    "    #                 'max_iter': 1000,\n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'name': 'Logistic_Regression_Architecture_2',\n",
    "    #             'params': {\n",
    "    #                 'C': 1.0,\n",
    "    #                 'penalty': 'l2',\n",
    "    #                 'solver': 'saga',\n",
    "    #                 'max_iter': 1000,\n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'name': 'Logistic_Regression_Architecture_3',\n",
    "    #             'params': {\n",
    "    #                 'C': 10.0,\n",
    "    #                 'penalty': 'l2',\n",
    "    #                 'solver': 'saga',\n",
    "    #                 'max_iter': 1000,\n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         }\n",
    "        \n",
    "    #     ],\n",
    "    #     'model_class': LogisticRegression\n",
    "    # },\n",
    "    \n",
    "    # ============================================\n",
    "    # MODELO 2: RANDOM FOREST\n",
    "    # ============================================\n",
    "    # 'Random_Forest': {\n",
    "    #     'architectures': [\n",
    "    #         {\n",
    "    #             'name': 'Random_Forest_Architecture_1',\n",
    "    #             'params': {\n",
    "    #                 'n_estimators': 100,  \n",
    "    #                 'max_depth': 15,     \n",
    "    #                 'min_samples_split': 5,\n",
    "    #                 'min_samples_leaf': 2,\n",
    "    #                 'max_features': 'sqrt',\n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'name': 'Random_Forest_Architecture_2',  \n",
    "    #             'params': {\n",
    "    #                 'n_estimators': 150,  \n",
    "    #                 'max_depth': 20,      \n",
    "    #                 'min_samples_split': 2,\n",
    "    #                 'min_samples_leaf': 1,\n",
    "    #                 'max_features': 'sqrt',  \n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'name': 'Random_Forest_Architecture_3',\n",
    "    #             'params': {\n",
    "    #                 'n_estimators': 220,       \n",
    "    #                 'max_depth': 25,            \n",
    "    #                 'min_samples_split': 2,\n",
    "    #                 'min_samples_leaf': 1,\n",
    "    #                 'max_features': 'sqrt',\n",
    "    #                 'random_state': 42,\n",
    "    #                 'class_weight': 'balanced',\n",
    "    #                 'n_jobs': -1\n",
    "    #             }\n",
    "    #         },\n",
    "    #     ],\n",
    "    #     'model_class': RandomForestClassifier\n",
    "    # },\n",
    "    \n",
    "    # ============================================\n",
    "    # MODELO 3: XGBOOST\n",
    "    # ============================================\n",
    "    'XGBoost': {\n",
    "        'architectures': [\n",
    "           \n",
    "            {\n",
    "                'name': 'XGBoost_Architecture_1',\n",
    "                'params': {\n",
    "                    'n_estimators': 1800,\n",
    "                    'max_depth': 14,\n",
    "                    'learning_rate': 0.015,\n",
    "                    'subsample': 0.65,\n",
    "                    'colsample_bytree': 0.55,\n",
    "                    'colsample_bylevel': 0.7,\n",
    "                    'colsample_bynode': 0.8,\n",
    "                    'gamma': 0.5,\n",
    "                    'min_child_weight': 10,\n",
    "                    'max_delta_step': 1,\n",
    "                    'reg_alpha': 0.7,\n",
    "                    'reg_lambda': 2.5,\n",
    "                    'random_state': 42,\n",
    "                    'eval_metric': 'logloss',\n",
    "                    'scale_pos_weight': class_weight_dict[1]/class_weight_dict[0],\n",
    "                    **XGBOOST_GPU_PARAMS\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'XGBoost_Architecture_2',\n",
    "                'params': {\n",
    "                    'n_estimators': 2500,\n",
    "                    'max_depth': 13,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'subsample': 0.6,\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'colsample_bylevel': 0.65,\n",
    "                    'colsample_bynode': 0.75,\n",
    "                    'gamma': 0.6,\n",
    "                    'min_child_weight': 12,\n",
    "                    'max_delta_step': 2,\n",
    "                    'reg_alpha': 1.0,\n",
    "                    'reg_lambda': 3.0,\n",
    "                    'random_state': 42,\n",
    "                    'eval_metric': 'logloss',\n",
    "                    'scale_pos_weight': class_weight_dict[1]/class_weight_dict[0],\n",
    "                    **XGBOOST_GPU_PARAMS\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'XGBoost_Architecture_3',\n",
    "                'params': {\n",
    "                    'n_estimators': 3000,\n",
    "                    'max_depth': 15,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'subsample': 0.6,\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'colsample_bylevel': 0.6,\n",
    "                    'colsample_bynode': 0.7,\n",
    "                    'gamma': 0.7,\n",
    "                    'min_child_weight': 15,\n",
    "                    'max_delta_step': 3,\n",
    "                    'reg_alpha': 1.5,\n",
    "                    'reg_lambda': 4.0,\n",
    "                    'random_state': 42,\n",
    "                    'eval_metric': 'logloss',\n",
    "                    'scale_pos_weight': class_weight_dict[1]/class_weight_dict[0],\n",
    "                    **XGBOOST_GPU_PARAMS\n",
    "                }\n",
    "            }\n",
    "\n",
    "        ],\n",
    "        'model_class': xgb.XGBClassifier\n",
    "    },\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "active_models = list(models_config.keys())\n",
    "if len(active_models) == 0:\n",
    "    raise ValueError(\"ERROR: No active models\")\n",
    "elif len(active_models) > 1:\n",
    "    raise ValueError(f\"ERROR: There are {len(active_models)} active models: {active_models}. Only ONE at a time.\")\n",
    "\n",
    "print(f\"Active model: {active_models[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee48d3",
   "metadata": {},
   "source": [
    "# 9. TRAIN ARCHITECTURES WITH ACCUMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebce749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL: XGBoost_0\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[1/3] Training: XGBoost_Architecture_1\n",
      "--------------------------------------------------------------------------------\n",
      "Training...\n",
      "Calculating metrics...\n",
      "\n",
      "RESULTS:\n",
      "Training time: 0.29 min \n",
      "\n",
      "Train Precision: 0.6386\n",
      "Train Recall: 0.7581\n",
      "Train Accuracy: 0.7491\n",
      "Train F1: 0.6932\n",
      "Train MCC: 0.4886\n",
      "\n",
      "Test Precision: 0.6385\n",
      "Test Recall: 0.7579\n",
      "Test Accuracy: 0.7490\n",
      "Test F1: 0.6931\n",
      "Test MCC: 0.4884\n",
      "Test ROC AUC: 0.8352\n",
      "\n",
      "Architecture data saved\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[2/3] Training: XGBoost_Architecture_2\n",
      "--------------------------------------------------------------------------------\n",
      "Training...\n",
      "Calculating metrics...\n",
      "\n",
      "RESULTS:\n",
      "Training time: 0.71 min \n",
      "\n",
      "Train Precision: 0.7091\n",
      "Train Recall: 0.8188\n",
      "Train Accuracy: 0.8066\n",
      "Train F1: 0.7600\n",
      "Train MCC: 0.6038\n",
      "\n",
      "Test Precision: 0.7089\n",
      "Test Recall: 0.8182\n",
      "Test Accuracy: 0.8064\n",
      "Test F1: 0.7596\n",
      "Test MCC: 0.6032\n",
      "Test ROC AUC: 0.9002\n",
      "\n",
      "Architecture data saved\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[3/3] Training: XGBoost_Architecture_3\n",
      "--------------------------------------------------------------------------------\n",
      "Training...\n",
      "Calculating metrics...\n",
      "\n",
      "RESULTS:\n",
      "Training time: 0.86 min \n",
      "\n",
      "Train Precision: 0.7476\n",
      "Train Recall: 0.8588\n",
      "Train Accuracy: 0.8387\n",
      "Train F1: 0.7993\n",
      "Train MCC: 0.6701\n",
      "\n",
      "Test Precision: 0.7458\n",
      "Test Recall: 0.8565\n",
      "Test Accuracy: 0.8371\n",
      "Test F1: 0.7973\n",
      "Test MCC: 0.6667\n",
      "Test ROC AUC: 0.9306\n",
      "\n",
      "Architecture data saved\n",
      "\n",
      "================================================================================\n",
      "COMPARING ARCHITECTURES\n",
      "================================================================================\n",
      "Architectures ranked:\n",
      "  3. XGBoost_Architecture_3: F1=0.7973\n",
      "  2. XGBoost_Architecture_2: F1=0.7596\n",
      "  1. XGBoost_Architecture_1: F1=0.6931\n",
      "\n",
      "BEST: XGBoost_Architecture_3\n",
      "\n",
      "================================================================================\n",
      "SAVING BEST MODEL\n",
      "================================================================================\n",
      "\n",
      "Architectures ranked:\n",
      "  3. XGBoost_Architecture_3: F1=0.7973\n",
      "  2. XGBoost_Architecture_2: F1=0.7596\n",
      "  1. XGBoost_Architecture_1: F1=0.6931\n",
      "\n",
      "BEST: XGBoost_Architecture_3\n",
      "\n",
      "================================================================================\n",
      "SAVING BEST MODEL\n",
      "================================================================================\n",
      "Best model saved\n",
      "\n",
      "================================================================================\n",
      "UPDATING ACCUMULATIVE SUMMARIES\n",
      "================================================================================\n",
      "Loading previous architectures...\n",
      "    • Previous: 9 | New: 3 | Total: 12\n",
      "  ✓ Saved: db/02a_classical_models/metrics/all_architectures_tested_comprehensive.xlsx\n",
      "  Loading previous best models...\n",
      "    • Previous: 3 | New: 1 | Total: 4\n",
      "Saved: db/02a_classical_models/comparative_tables/best_models_comparison_complete.xlsx\n",
      "\n",
      "Accumulation completed\n",
      "Model added: XGBoost_0\n",
      "Total models: 4\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in models_config.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MODEL: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    architecture_results = []\n",
    "    trained_models = []\n",
    "    \n",
    "    for arch_idx, architecture in enumerate(config['architectures'], 1):\n",
    "        arch_name = architecture['name']\n",
    "        arch_params = architecture['params']\n",
    "        \n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(f\"[{arch_idx}/3] Training: {arch_name}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        model = config['model_class'](**arch_params)\n",
    "        \n",
    "        print(f\"Training...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds() / 60\n",
    "        \n",
    "        print(f\"Calculating metrics...\")\n",
    "        metrics, y_pred_test, y_prob_test = calculate_comprehensive_metrics(\n",
    "            model, model_name, arch_name, X_train, X_test, \n",
    "            y_train, y_test, training_time, feature_names\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nRESULTS:\")\n",
    "        print(f\"Training time: {metrics['Training_Time_Minutes']:.2f} min \\n\")\n",
    "\n",
    "        print(f\"Train Precision: {metrics['Train_Precision']:.4f}\")\n",
    "        print(f\"Train Recall: {metrics['Train_Recall']:.4f}\")\n",
    "        print(f\"Train Accuracy: {metrics['Train_Accuracy']:.4f}\")\n",
    "        print(f\"Train F1: {metrics['Train_F1']:.4f}\")\n",
    "        print(f\"Train MCC: {metrics['Train_MCC']:.4f}\\n\")\n",
    "\n",
    "\n",
    "        print(f\"Test Precision: {metrics['Test_Precision']:.4f}\")\n",
    "        print(f\"Test Recall: {metrics['Test_Recall']:.4f}\")\n",
    "        print(f\"Test Accuracy: {metrics['Test_Accuracy']:.4f}\")\n",
    "        print(f\"Test F1: {metrics['Test_F1']:.4f}\")\n",
    "        print(f\"Test MCC: {metrics['Test_MCC']:.4f}\")\n",
    "        print(f\"Test ROC AUC: {metrics['Test_ROC_AUC']:.4f}\\n\")\n",
    "        \n",
    "        \n",
    "        architecture_results.append(metrics)\n",
    "        trained_models.append({\n",
    "            'architecture': arch_name,\n",
    "            'model': model,\n",
    "            'metrics': metrics,\n",
    "            'y_pred_test': y_pred_test,\n",
    "            'y_prob_test': y_prob_test\n",
    "        })\n",
    "        \n",
    "        # Save individual architecture\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_excel(f'db/02a_classical_models/metrics/by_architecture/{model_name}_{arch_name}_comprehensive_metrics.xlsx', \n",
    "                           index=False, engine='openpyxl')\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_df = pd.DataFrame(cm, index=['True_Others', 'True_Displacement'],\n",
    "                             columns=['Pred_Others', 'Pred_Displacement'])\n",
    "        cm_df.to_excel(f'db/02a_classical_models/model_data/confusion_matrices/by_architecture/{model_name}_{arch_name}_confusion_matrix.xlsx', \n",
    "                       engine='openpyxl')\n",
    "        \n",
    "        if y_prob_test is not None:\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Thresholds': thresholds, 'AUC': roc_auc})\n",
    "            roc_df.to_excel(f'db/02a_classical_models/model_data/roc_data/by_architecture/{model_name}_{arch_name}_roc_curve.xlsx', \n",
    "                           index=False, engine='openpyxl')\n",
    "        \n",
    "        report = classification_report(y_test, y_pred_test, target_names=['Others', 'Displacement'], output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_excel(f'db/02a_classical_models/metrics/by_architecture/{model_name}_{arch_name}_classification_report.xlsx', \n",
    "                          engine='openpyxl')\n",
    "        \n",
    "        params_df = pd.DataFrame([arch_params])\n",
    "        params_df.to_excel(f'db/02a_classical_models/model_data/hyperparameters/{model_name}_{arch_name}_hyperparameters.xlsx', \n",
    "                          index=False, engine='openpyxl')\n",
    "        \n",
    "        print(f\"Architecture data saved\")\n",
    "    \n",
    "    # Compare architectures\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMPARING ARCHITECTURES\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    comparison_df = pd.DataFrame(architecture_results).sort_values('Test_F1', ascending=False)\n",
    "    comparison_df.to_excel(f'db/02a_classical_models/model_data/architecture_comparisons/{model_name}_architectures_comparison.xlsx', \n",
    "                          index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"Architectures ranked:\")\n",
    "    for idx, row in comparison_df.iterrows():\n",
    "        print(f\"  {idx+1}. {row['Architecture']}: F1={row['Test_F1']:.4f}\")\n",
    "    \n",
    "    best_arch_name = comparison_df.iloc[0]['Architecture']\n",
    "    print(f\"\\nBEST: {best_arch_name}\")\n",
    "    \n",
    "    best_model_data = None\n",
    "    for trained_data in trained_models:\n",
    "        if trained_data['architecture'] == best_arch_name:\n",
    "            best_model_data = trained_data\n",
    "            break\n",
    "\n",
    "    # Save best model\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAVING BEST MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    comparison_df = pd.DataFrame(architecture_results).sort_values('Test_F1', ascending=False)\n",
    "    comparison_df.to_excel(f'db/02a_classical_models/model_data/architecture_comparisons/{model_name}_architectures_comparison.xlsx', \n",
    "                          index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"\\nArchitectures ranked:\")\n",
    "    for idx, row in comparison_df.iterrows():\n",
    "        print(f\"  {idx+1}. {row['Architecture']}: F1={row['Test_F1']:.4f}\")\n",
    "    \n",
    "    best_arch_name = comparison_df.iloc[0]['Architecture']\n",
    "    print(f\"\\nBEST: {best_arch_name}\")\n",
    "    \n",
    "    best_model_data = None\n",
    "    for trained_data in trained_models:\n",
    "        if trained_data['architecture'] == best_arch_name:\n",
    "            best_model_data = trained_data\n",
    "            break\n",
    "    \n",
    "    # Save best model\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAVING BEST MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    joblib.dump(best_model_data['model'], f'db/02a_classical_models/saved_models/{model_name}_best_model.pkl')\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Sample_Index': range(len(y_test)),\n",
    "        'True_Label': y_test,\n",
    "        'Predicted_Label': best_model_data['y_pred_test'],\n",
    "        'Correct': y_test == best_model_data['y_pred_test']\n",
    "    })\n",
    "    if best_model_data['y_prob_test'] is not None:\n",
    "        predictions_df['Probability_Class_1'] = best_model_data['y_prob_test']\n",
    "    predictions_df.to_csv(f'db/02a_classical_models/predictions/{model_name}_best_predictions.csv', index=False)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, best_model_data['y_pred_test'])\n",
    "    cm_df = pd.DataFrame(cm, index=['True_Others', 'True_Displacement'], \n",
    "                         columns=['Pred_Others', 'Pred_Displacement'])\n",
    "    cm_df.to_excel(f'db/02a_classical_models/model_data/confusion_matrices/{model_name}_best_confusion_matrix.xlsx', \n",
    "                   engine='openpyxl')\n",
    "    \n",
    "    if best_model_data['y_prob_test'] is not None:\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, best_model_data['y_prob_test'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Thresholds': thresholds, 'AUC': roc_auc})\n",
    "        roc_df.to_excel(f'db/02a_classical_models/model_data/roc_data/{model_name}_best_roc_curve.xlsx', \n",
    "                       index=False, engine='openpyxl')\n",
    "    \n",
    "    if hasattr(best_model_data['model'], 'feature_importances_'):\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': best_model_data['model'].feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        importance_df.to_excel(f'db/02a_classical_models/model_data/feature_importance/{model_name}_best_feature_importance.xlsx', \n",
    "                              index=False, engine='openpyxl')\n",
    "    elif hasattr(best_model_data['model'], 'coef_'):\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': best_model_data['model'].coef_[0]\n",
    "        })\n",
    "        importance_df['Abs_Coefficient'] = importance_df['Coefficient'].abs()\n",
    "        importance_df = importance_df.sort_values('Abs_Coefficient', ascending=False)\n",
    "        importance_df.to_excel(f'db/02a_classical_models/model_data/feature_importance/{model_name}_best_coefficients.xlsx', \n",
    "                              index=False, engine='openpyxl')\n",
    "    \n",
    "    pd.DataFrame([best_model_data['metrics']]).to_excel(\n",
    "        f'db/02a_classical_models/metrics/{model_name}_best_comprehensive_metrics.xlsx', \n",
    "        index=False, engine='openpyxl')\n",
    "    \n",
    "    report = classification_report(y_test, best_model_data['y_pred_test'], \n",
    "                                   target_names=['Others', 'Displacement'], output_dict=True)\n",
    "    pd.DataFrame(report).transpose().to_excel(\n",
    "        f'db/02a_classical_models/metrics/{model_name}_best_classification_report.xlsx', \n",
    "        engine='openpyxl')\n",
    "    \n",
    "    best_params = None\n",
    "    for arch in config['architectures']:\n",
    "        if arch['name'] == best_arch_name:\n",
    "            best_params = arch['params']\n",
    "            break\n",
    "    if best_params:\n",
    "        pd.DataFrame([best_params]).to_excel(\n",
    "            f'db/02a_classical_models/model_data/hyperparameters/{model_name}_best_hyperparameters.xlsx', \n",
    "            index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"Best model saved\")\n",
    "    \n",
    "    # ACCUMULATION\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"UPDATING ACCUMULATIVE SUMMARIES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # All architectures\n",
    "    all_arch_path = 'db/02a_classical_models/metrics/all_architectures_tested_comprehensive.xlsx'\n",
    "    new_arch_results = pd.DataFrame(architecture_results)\n",
    "    \n",
    "    if os.path.exists(all_arch_path):\n",
    "        print(f\"Loading previous architectures...\")\n",
    "        previous_arch = pd.read_excel(all_arch_path)\n",
    "        previous_arch = previous_arch[previous_arch['Model'] != model_name]\n",
    "        all_arch_combined = pd.concat([previous_arch, new_arch_results], ignore_index=True)\n",
    "        print(f\"    • Previous: {len(previous_arch)} | New: {len(new_arch_results)} | Total: {len(all_arch_combined)}\")\n",
    "    else:\n",
    "        print(f\"Creating new file...\")\n",
    "        all_arch_combined = new_arch_results\n",
    "        print(f\"Total: {len(all_arch_combined)}\")\n",
    "    \n",
    "    all_arch_combined.to_excel(all_arch_path, index=False, engine='openpyxl')\n",
    "    print(f\"  ✓ Saved: {all_arch_path}\")\n",
    "    \n",
    "    # Best models\n",
    "    best_models_path = 'db/02a_classical_models/comparative_tables/best_models_comparison_complete.xlsx'\n",
    "    new_best_model = pd.DataFrame([best_model_data['metrics']])\n",
    "    \n",
    "    if os.path.exists(best_models_path):\n",
    "        print(f\"  Loading previous best models...\")\n",
    "        previous_best = pd.read_excel(best_models_path)\n",
    "        previous_best = previous_best[previous_best['Model'] != model_name]\n",
    "        best_combined = pd.concat([previous_best, new_best_model], ignore_index=True)\n",
    "        best_combined = best_combined.sort_values('Test_F1', ascending=False).reset_index(drop=True)\n",
    "        print(f\"    • Previous: {len(previous_best)} | New: 1 | Total: {len(best_combined)}\")\n",
    "    else:\n",
    "        print(f\"Creating new file...\")\n",
    "        best_combined = new_best_model\n",
    "        print(f\"Total: {len(best_combined)}\")\n",
    "    \n",
    "    best_combined.to_excel(best_models_path, index=False, engine='openpyxl')\n",
    "    print(f\"Saved: {best_models_path}\")\n",
    "    \n",
    "    # Publication-ready\n",
    "    pub_cols = [\n",
    "        'Model', 'Architecture', 'Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_F1',\n",
    "        'Test_Specificity', 'Test_G_Mean', 'Test_MCC', 'Test_Balanced_Accuracy',\n",
    "        'Test_ROC_AUC', 'Test_Kappa', 'Test_Log_Loss',\n",
    "        'Training_Time_Minutes', 'Inference_Time_ms_per_sample',\n",
    "        'Model_Size_MB', 'F1_Gap_Train_Test', 'Number_of_Features'\n",
    "    ]\n",
    "    pub_table = best_combined[pub_cols].copy()\n",
    "    numeric_cols = pub_table.select_dtypes(include=[np.number]).columns\n",
    "    pub_table[numeric_cols] = pub_table[numeric_cols].round(4)\n",
    "    pub_table.to_excel('db/02a_classical_models/comparative_tables/best_models_comparison_publication_ready.xlsx', \n",
    "                       index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"\\nAccumulation completed\")\n",
    "    print(f\"Model added: {model_name}\")\n",
    "    print(f\"Total models: {len(best_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3db77",
   "metadata": {},
   "source": [
    "# 10. TRAINING COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe32c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT STATE:\n",
      "Total models: 4\n",
      "\n",
      "Top 3:\n",
      "    1. Random_Forest: F1=0.8943\n",
      "    2. XGBoost: F1=0.8274\n",
      "    3. XGBoost_0: F1=0.7973\n",
      "\n",
      "All trained:\n",
      "Random_Forest\n",
      "XGBoost\n",
      "XGBoost_0\n",
      "Logistic_Regression\n",
      "NEXT: Comment current model, uncomment next, run again\n"
     ]
    }
   ],
   "source": [
    "best_models_path = 'db/02a_classical_models/comparative_tables/best_models_comparison_complete.xlsx'\n",
    "if os.path.exists(best_models_path):\n",
    "    current_best = pd.read_excel(best_models_path).sort_values('Test_F1', ascending=False)\n",
    "    \n",
    "    print(f\"\\nCURRENT STATE:\")\n",
    "    print(f\"Total models: {len(current_best)}\")\n",
    "    print(f\"\\nTop 3:\")\n",
    "    for idx, row in current_best.head(3).iterrows():\n",
    "        print(f\"    {idx+1}. {row['Model']}: F1={row['Test_F1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nAll trained:\")\n",
    "    for model in current_best['Model'].tolist():\n",
    "        print(f\"{model}\")\n",
    "else:\n",
    "    print(\"\\nNo models found\")\n",
    "\n",
    "print(\"NEXT: Comment current model, uncomment next, run again\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
